name: Update Hugging Face Space (crawl + upload)

on:
  schedule:
    - cron: "*/5 * * * *"   # every 5 minutes (UTC)
  workflow_dispatch:
  push:
    paths:
      - "crawler/**"
      - "hf_space/**"
      - ".github/workflows/update_hf_space.yml"

# 防止 5 分钟一次导致任务堆积/并发（你的 crawl 可能 > 5 分钟）
concurrency:
  group: ca-crawl-upload
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  crawl_and_upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Debug - print trigger time
        run: |
          echo "event=$GITHUB_EVENT_NAME"
          echo "UTC now:"
          date -u
          echo "runner now:"
          date

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install crawler deps
        run: |
          python -m pip install --upgrade pip
          pip install -r crawler/requirements.txt

      - name: Crawl website
        run: python crawler/crawl_site.py
        env:
          CA_BASE_URL: https://www.cheshireacademy.org
          CA_SOURCES_DIR: sources
          CA_MAX_PAGES: "2500"
          CA_ALLOWED_DOMAINS: "cheshireacademy.org,www.cheshireacademy.org"

      - name: Prepare HF Space folder (ensure dir + sync sources)
        run: |
          mkdir -p hf_space
          rm -rf hf_space/sources
          cp -r sources hf_space/sources
          ls -la hf_space | head -n 50

      - name: Upload Space folder to Hugging Face
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_SPACE_ID: ${{ secrets.HF_SPACE_ID }}
          HF_SPACE_DIR: hf_space
        run: |
          python crawler/upload_to_hf.py
