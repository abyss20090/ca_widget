name: Update Hugging Face Space (crawl + upload)

on:
  schedule:
    - cron: "0 0 * * *"   
  workflow_dispatch:
  push:
    paths:
      - "crawler/**"
      - "hf_space/**"
      - ".github/workflows/update_hf_space.yml"

permissions:
  contents: read

jobs:
  crawl_and_upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install crawler deps
        run: |
          python -m pip install --upgrade pip
          pip install -r crawler/requirements.txt

      - name: Crawl website
        run: python crawler/crawl_site.py
        env:
          CA_BASE_URL: https://www.cheshireacademy.org
          CA_SOURCES_DIR: sources
          CA_MAX_PAGES: "2500"
          CA_ALLOWED_DOMAINS: "cheshireacademy.org,www.cheshireacademy.org"

      - name: Upload Space folder to Hugging Face
        run: python crawler/upload_to_hf.py
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_SPACE_ID: ${{ secrets.HF_SPACE_ID }}
          HF_SPACE_DIR: hf_space
          HF_HUB_ENABLE_HF_TRANSFER: "1"
          
      - name: Prepare HF Space folder (ensure dir + sync sources)
        run: |
          mkdir -p hf_space
          rm -rf hf_space/sources
          cp -r sources hf_space/sources
          ls -la hf_space | head -n 50

      - name: Upload Space folder to Hugging Face
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_SPACE_ID: ${{ secrets.HF_SPACE_ID }}
          HF_SPACE_DIR: hf_space
        run: |
          python crawler/upload_to_hf.py
